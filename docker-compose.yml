# =============================================================================
# n8n Production Stack — AWS EC2 t3.xlarge (4 vCPU, 16 GB RAM)
# =============================================================================
# Fully Podman-compatible (tested against podman-compose 1.x)
#
# Usage:
#   podman-compose up -d
#   podman-compose logs -f
#   podman-compose down
#
# Podman compatibility notes:
#   - Direct bind mounts instead of named volumes with driver_opts
#     (driver_opts is silently ignored by podman-compose)
#   - Simple depends_on (no condition: service_healthy)
#     (broken in podman-compose; services handle retries internally)
#   - nickfedor/watchtower (maintained fork of archived containrrr/watchtower)
#   - Podman socket path configurable via PODMAN_SOCKET env var
# =============================================================================

version: "3.8"

networks:
  n8n-net:
    driver: bridge

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL 16 — Production Tuned
  # ---------------------------------------------------------------------------
  # Memory budget: 4 GB (of 16 GB total)
  # CPU budget: 1.5 cores (of 4 total)
  # Key tuning: shared_buffers=1GB, work_mem=32MB, max_connections=60
  # ---------------------------------------------------------------------------
  postgres:
    image: docker.io/library/postgres:latest
    container_name: n8n-postgres
    restart: unless-stopped
    networks:
      - n8n-net
    # NOTE: No port mapping — PostgreSQL is only accessible within n8n-net
    # For debugging, temporarily add:  ports: ["127.0.0.1:5432:5432"]
    environment:
      TZ: Asia/Kolkata
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      # Direct bind mounts (podman-compose ignores driver_opts on named volumes)
      - ./postgres/data:/var/lib/postgresql/data:Z
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro,Z
      # Init scripts run ONLY on first boot (empty data dir). Safe to keep mounted.
      - ./postgres/init:/docker-entrypoint-initdb.d:ro,Z
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    deploy:
      resources:
        limits:
          memory: 4g
          cpus: "1.5"
        reservations:
          memory: 2g
          cpus: "0.5"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME} || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # n8n — Main Application
  # ---------------------------------------------------------------------------
  # Memory budget: 6 GB (of 16 GB total)
  # CPU budget: 1.5 cores (of 4 total)
  # Node.js heap: 4096 MB (within 6 GB container limit)
  #
  # Startup: n8n retries DB connection internally on launch (built-in).
  # With restart: unless-stopped, even if PG isn't ready, n8n will
  # restart and successfully connect once PG is healthy.
  # ---------------------------------------------------------------------------
  n8n:
    image: docker.n8n.io/n8nio/n8n:stable
    container_name: n8n
    restart: unless-stopped
    networks:
      - n8n-net
    ports:
      - "5678:5678"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - postgres
    environment:
      # --- Timezone ---
      TZ: Asia/Kolkata
      GENERIC_TIMEZONE: Asia/Kolkata

      # --- Database ---
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: n8n-postgres
      DB_POSTGRESDB_PORT: "5432"
      DB_POSTGRESDB_DATABASE: ${DB_NAME}
      DB_POSTGRESDB_USER: ${DB_USER}
      DB_POSTGRESDB_PASSWORD: ${DB_PASSWORD}
      DB_POSTGRESDB_SCHEMA: public
      DB_POSTGRESDB_POOL_SIZE: "20"

      # --- Hosting ---
      N8N_HOST: ${N8N_HOST}
      N8N_PROTOCOL: https
      WEBHOOK_URL: https://${N8N_HOST}
      N8N_PORT: "5678"
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}
      N8N_SECURE_COOKIE: "true"
      NODE_ENV: production

      # --- Node.js Performance ---
      # 4 GB heap within 6 GB container limit
      NODE_OPTIONS: "--max-old-space-size=4096"

      # --- Task Runners (External Mode) ---
      N8N_RUNNERS_ENABLED: "true"
      N8N_RUNNERS_MODE: external
      N8N_RUNNERS_BROKER_LISTEN_ADDRESS: "0.0.0.0"
      N8N_RUNNERS_AUTH_TOKEN: ${RUNNERS_AUTH_TOKEN}
      N8N_NATIVE_PYTHON_RUNNER: "true"

      # --- Execution Pruning ---
      EXECUTIONS_DATA_PRUNE: "true"
      EXECUTIONS_DATA_MAX_AGE: "336"  # 14 days
      EXECUTIONS_DATA_PRUNE_MAX_COUNT: "50000"

      # --- Logging ---
      N8N_LOG_LEVEL: warn
      N8N_LOG_OUTPUT: console

      # --- Diagnostics ---
      N8N_DIAGNOSTICS_ENABLED: "false"
    volumes:
      - ./n8n/data:/home/node/.n8n:Z
    deploy:
      resources:
        limits:
          memory: 6g
          cpus: "1.5"
        reservations:
          memory: 3g
          cpus: "0.5"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:5678/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # n8n Task Runners (JavaScript + Python)
  # ---------------------------------------------------------------------------
  # Memory budget: 3 GB (of 16 GB total)
  # CPU budget: 1.0 core (of 4 total)
  #
  # Startup: Runner auto-retries broker connection. If n8n isn't ready,
  # restart policy handles reconnection.
  # ---------------------------------------------------------------------------
  n8n-runners:
    build:
      context: ./runners
      dockerfile: Dockerfile
    image: n8n-runners-python:latest
    container_name: n8n-runners
    restart: unless-stopped
    networks:
      - n8n-net
    depends_on:
      - n8n
    environment:
      N8N_RUNNERS_TASK_BROKER_URI: http://n8n:5679
      N8N_RUNNERS_AUTH_TOKEN: ${RUNNERS_AUTH_TOKEN}
      N8N_RUNNERS_AUTO_SHUTDOWN_TIMEOUT: "60"
      N8N_RUNNERS_TASK_TIMEOUT: "600"
      N8N_RUNNERS_MAX_CONCURRENCY: "15"
      GENERIC_TIMEZONE: Asia/Kolkata
    deploy:
      resources:
        limits:
          memory: 3g
          cpus: "1.0"
        reservations:
          memory: 1g
          cpus: "0.25"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:5681/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ---------------------------------------------------------------------------
  # Watchtower — Update Monitor (notification only, NO auto-update)
  # ---------------------------------------------------------------------------
  # nickfedor/watchtower — actively maintained fork of the archived
  # containrrr/watchtower (archived Dec 2025, incompatible with newer APIs).
  # Drop-in replacement: same config, same env vars, just a different image.
  #
  # Checks labeled containers every 24h and logs when updates are available.
  # Does NOT auto-pull or restart.
  #
  # Manual update workflow:
  #   podman-compose pull n8n
  #   podman-compose up -d n8n
  # ---------------------------------------------------------------------------
  watchtower:
    image: docker.io/nickfedor/watchtower:latest
    container_name: watchtower
    restart: unless-stopped
    environment:
      TZ: Asia/Kolkata
      WATCHTOWER_MONITOR_ONLY: "true"
      WATCHTOWER_POLL_INTERVAL: "86400"
      WATCHTOWER_LABEL_ENABLE: "true"
      WATCHTOWER_DEBUG: "false"
      WATCHTOWER_CLEANUP: "false"
      # --- Notifications (configure later, after n8n is stable) ---
      #
      # Option A: Email (if you have SMTP)
      # WATCHTOWER_NOTIFICATIONS: email
      # WATCHTOWER_NOTIFICATION_EMAIL_FROM: watchtower@iitbacr.space
      # WATCHTOWER_NOTIFICATION_EMAIL_TO: your-email@iitbacr.space
      # WATCHTOWER_NOTIFICATION_EMAIL_SERVER: smtp.iitbacr.space
      # WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT: "587"
      # WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER: user
      # WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD: pass
      #
      # Option B: Slack webhook
      # WATCHTOWER_NOTIFICATIONS: slack
      # WATCHTOWER_NOTIFICATION_SLACK_HOOK_URL: https://hooks.slack.com/services/xxx
      # WATCHTOWER_NOTIFICATION_SLACK_CHANNEL: "#infra-alerts"
      #
      # Option C: n8n webhook (set up after n8n is running)
      # WATCHTOWER_NOTIFICATIONS: shoutrrr
      # WATCHTOWER_NOTIFICATION_URL: generic+https://n8n.iitbacr.space/webhook/watchtower
    volumes:
      # Podman socket path — auto-detected by deploy.sh and written to .env
      # Rootful:  /run/podman/podman.sock
      # Rootless: /run/user/<UID>/podman/podman.sock
      - ${PODMAN_SOCKET}:/var/run/docker.sock:ro
    labels:
      - "com.centurylinklabs.watchtower.enable=false"
    deploy:
      resources:
        limits:
          memory: 128m
          cpus: "0.1"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "2"
